---
title: "ANGSD - RNAseq Project"
author: "Mir-Mammad Javad-zada (Miri)"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  html_document: 
    code_folding: show
    df_print: paged
    theme: cosmo
    toc: true
    toc_depth: 2
    toc_float: true
---

# Details regarding the data
-My data is deposited in [GEO](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE211993) as GSE211993

-I have downloaded my raw sequences from [SRA](https://www.ncbi.nlm.nih.gov/Traces/study/?acc=PRJNA873113&o=acc_s%3Aa) (40 FASTQ pair end can be found using ID PRJNA873113)

-My publication is [The transcriptomic landscape of neurons carrying PSEN1 mutations reveals changes in extracellular matrix components and non-coding gene expression](https://www.sciencedirect.com/science/article/pii/S0969996122003722?via%3Dihub=#s0010)

-The data were generated by researchers involved in the studies cited, including Tubsuwan et al. (2016), Li et al. (2016), Pires et al. (2016), Poon et al. (2016), Shi et al. (2012), and Haukedal et al. (2022), among others involved in the generation, differentiation, and characterization of hiPSCs and the subsequent RNA sequencing and analysis.

-RNA data was extracted using the RNeasy® Plus Mini Kit (Qiagen, 74,134) according to the manufacturer's protocol.

-Bulk Poly(A) and total RNA libraries were constructed for 5 replicates according to BGI protocols and sequenced with BGIseq (DNBseq, 2 × 100 nt, stranded paired-end).

-Cells of interest were human induced pluripotent stem cells (hiPSCs) were differentiated into glutamatergic forebrain neurons.

-The experimental condition involved the differentiation of hiPSCs into glutamatergic forebrain neurons using a modified version of a protocol exploiting dual SMAD inhibition with LDN-193189 as an analogue for Noggin, targeting mutations PSEN1 L150P and PSEN1 A79V through CRISPR-Cas9 gene editing.

-The sequencing was conducted with BGIseq (DNBseq, 2 × 100 nt, stranded paired-end).

# Prerequisite - Conda environment
Create rna_seq_analysis.yaml to create conda environment with all necessary tools:
```{bash, eval=FALSE}
name: rna_seq_analysis
channels:
  - conda-forge
  - bioconda
  - defaults
dependencies:
  - sra-tools=3.1.0
  - fastqc=0.12.1
  - multiqc=1.21
  - cutadapt=4.7
  - bbmap=39.06
  - star=2.7.11b
  - samtools=1.19.2
  - subread=2.0.6
  - wget=1.21.4
```
Run the following command to create new environment with specified name:
```{bash, eval=FALSE}
conda env create -f rna_seq_analysis.yaml
```
This environment contains all you need for the further analysis, just activate it via:
```{bash, eval=FALSE}
conda activate rna_seq_analysis
```

# Prerequisite - Interactive shell/slurm
You can either run following scripts in interactive shell on Weill Cornell Cayuga server using:
```{bash, eval=FALSE}
srun -n1 --pty --partition=angsd_class --mem=40G bash -i
```
or you can edit scripts to run them using batch scheduler of your choice.

# Prerequisite - Script location
All scripts are located at `/athena/angsd/scratch/mij4011/homework/project`

# Prerequisite - Master Script
Master Script can be used to run all the tasks in a series to avoid unnecessary repetitiveness and improve reproducibility.

master.sh:
```{bash, eval=FALSE}
#!/bin/bash

# Stop on error
set -e

# Activate environment
conda activate rna_seq_analysis

# Step 1: Download Data
bash download_data.sh

# Step 2: Quality Control
bash fastqc.sh

# Step 3: Adapter Trimming
bash cutadapt.sh

# Step 4: rRNA Removal
bash silva_database_download.sh
bash run_bbduk.sh

# Quality control after processing
bash processed_multiqc.sh

# Step 5: Alignment
bash hg38.sh
bash index.sh
bash star.sh

# Quality check for mapping
bash mapping_quality.sh

# Step 6: Feature Counts
bash featurecounts.sh

echo "Analysis Complete"
```

# 1. Writing a script to download fastq files.

download_data.sh:
```{bash, eval=FALSE}
# ! / bin / bash -i

# Define an array of accession numbers from downloaded metadata file from SRA
ACCESSIONS=(
SRR21190736 SRR21190737 SRR21190738 SRR21190739 SRR21190740
SRR21190741 SRR21190742 SRR21190743 SRR21190744 SRR21190745
SRR21190746 SRR21190747 SRR21190748 SRR21190749 SRR21190750
SRR21190751 SRR21190752 SRR21190753 SRR21190754 SRR21190755
SRR21190756 SRR21190757 SRR21190758 SRR21190759 SRR21190760
SRR21190761 SRR21190762 SRR21190763 SRR21190764 SRR21190765
SRR21190766 SRR21190767 SRR21190768 SRR21190769 SRR21190770
SRR21190771 SRR21190772 SRR21190773 SRR21190774 SRR21190775
)

# Create a directory named "fastq" and move into it
mkdir -p fastq
cd fastq

# Loop through the accession numbers and download each one
for ACCESSION in "${ACCESSIONS[@]}"; do
    echo "Downloading $ACCESSION..."
    fasterq-dump "$ACCESSION" --split-files --skip-technical --threads 4
done

echo "Download completed."

# Move back to the original directory
cd ..
```

# 2. Quality control with FastQC and MultiQC
fastqc.sh:
```{bash, eval=FALSE}
#!/bin/bash

FASTQ_DIR="fastq"

# Output directory for FastQC results
OUTPUT_DIR="fastqc_results"

# Create output directory if it doesn't exist
mkdir -p "$OUTPUT_DIR" multiqc

# Run FastQC on all FASTQ files in the directory
fastqc -o "$OUTPUT_DIR" -t 40 "$FASTQ_DIR"/*.fastq

# Run MultiQC to combine the FastQC reports
multiqc "$OUTPUT_DIR" -o multiqc
```

<iframe src="multiqc_reports/multiqc_preprocessed.pdf" width="100%" height="600"></iframe>


# 3. Trimming data

According to the protocol, the next step in the analysis is trimming the adapters.

The sequencing was performed using BGIseq (DNBseq) technology and libraries were constructed following BGI protocols, the adapters you need to trim will likely be specific to BGI's sequencing platforms. I have found out that adapter for forward strand is `AAGTCGGAGGCCAAGCGGTCTTAGGAAGACAA` and for backward is `AAGTCGGATCGTAGCCATGTCGTTCTGTGAGCCAAGGAGTTG`. I am going to test it using the following script.
adapter_test.sh:
```{bash, eval=FALSE}
#!/bin/bash

# Adapter sequences
FORWARD_ADAPTER="AAGTCGGAGGCCAAGCGGTCTTAGGAAGACAA"
REVERSE_ADAPTER="AAGTCGGATCGTAGCCATGTCGTTCTGTGAGCCAAGGAGTTG"
FASTQ_DIR="path/to/fastq_files"

# Loop through all FASTQ files in the specified directory
for FASTQ_FILE in $FASTQ_DIR/*.fastq; do
    # Determine if the file is forward or reverse based on its name
    if [[ $FASTQ_FILE =~ _1.fastq$ ]]; then
        # Search for the forward adapter
        ADAPTER_SEQ=$FORWARD_ADAPTER
        COUNT=$(grep -o "$ADAPTER_SEQ" "$FASTQ_FILE" | wc -l)
        echo "Found $COUNT instances of the forward adapter sequence in $FASTQ_FILE"
    elif [[ $FASTQ_FILE =~ _2.fastq$ ]]; then
        # Search for the reverse adapter
        ADAPTER_SEQ=$REVERSE_ADAPTER
        COUNT=$(grep -o "$ADAPTER_SEQ" "$FASTQ_FILE" | wc -l)
        echo "Found $COUNT instances of the reverse adapter sequence in $FASTQ_FILE"
    else
        echo "Skipping $FASTQ_FILE: not recognized as forward or reverse."
    fi
done
```
output of testing:
```{bash, eval=FALSE}

Found 6058 instances of the forward adapter sequence in fastq/SRR21190736_1.fastq
Found 928 instances of the reverse adapter sequence in fastq/SRR21190736_2.fastq
Found 5027 instances of the forward adapter sequence in fastq/SRR21190737_1.fastq
Found 752 instances of the reverse adapter sequence in fastq/SRR21190737_2.fastq
Found 5326 instances of the forward adapter sequence in fastq/SRR21190738_1.fastq
Found 881 instances of the reverse adapter sequence in fastq/SRR21190738_2.fastq
Found 3339 instances of the forward adapter sequence in fastq/SRR21190739_1.fastq
Found 600 instances of the reverse adapter sequence in fastq/SRR21190739_2.fastq
Found 5090 instances of the forward adapter sequence in fastq/SRR21190740_1.fastq
Found 876 instances of the reverse adapter sequence in fastq/SRR21190740_2.fastq
Found 6257 instances of the forward adapter sequence in fastq/SRR21190741_1.fastq
Found 1025 instances of the reverse adapter sequence in fastq/SRR21190741_2.fastq
Found 3346 instances of the forward adapter sequence in fastq/SRR21190742_1.fastq
Found 553 instances of the reverse adapter sequence in fastq/SRR21190742_2.fastq
Found 4611 instances of the forward adapter sequence in fastq/SRR21190743_1.fastq
Found 663 instances of the reverse adapter sequence in fastq/SRR21190743_2.fastq
Found 4848 instances of the forward adapter sequence in fastq/SRR21190744_1.fastq
Found 858 instances of the reverse adapter sequence in fastq/SRR21190744_2.fastq
Found 4369 instances of the forward adapter sequence in fastq/SRR21190745_1.fastq
Found 1021 instances of the reverse adapter sequence in fastq/SRR21190745_2.fastq
Found 7493 instances of the forward adapter sequence in fastq/SRR21190746_1.fastq
Found 1434 instances of the reverse adapter sequence in fastq/SRR21190746_2.fastq
Found 5330 instances of the forward adapter sequence in fastq/SRR21190747_1.fastq
Found 982 instances of the reverse adapter sequence in fastq/SRR21190747_2.fastq
Found 6193 instances of the forward adapter sequence in fastq/SRR21190748_1.fastq
Found 1116 instances of the reverse adapter sequence in fastq/SRR21190748_2.fastq
Found 5028 instances of the forward adapter sequence in fastq/SRR21190749_1.fastq
Found 905 instances of the reverse adapter sequence in fastq/SRR21190749_2.fastq
Found 5482 instances of the forward adapter sequence in fastq/SRR21190750_1.fastq
Found 869 instances of the reverse adapter sequence in fastq/SRR21190750_2.fastq
Found 4665 instances of the forward adapter sequence in fastq/SRR21190751_1.fastq
Found 689 instances of the reverse adapter sequence in fastq/SRR21190751_2.fastq
Found 4057 instances of the forward adapter sequence in fastq/SRR21190752_1.fastq
Found 770 instances of the reverse adapter sequence in fastq/SRR21190752_2.fastq
Found 5233 instances of the forward adapter sequence in fastq/SRR21190753_1.fastq
Found 909 instances of the reverse adapter sequence in fastq/SRR21190753_2.fastq
Found 3782 instances of the forward adapter sequence in fastq/SRR21190754_1.fastq
Found 749 instances of the reverse adapter sequence in fastq/SRR21190754_2.fastq
Found 3413 instances of the forward adapter sequence in fastq/SRR21190755_1.fastq
Found 633 instances of the reverse adapter sequence in fastq/SRR21190755_2.fastq
Found 2812 instances of the forward adapter sequence in fastq/SRR21190756_1.fastq
Found 358 instances of the reverse adapter sequence in fastq/SRR21190756_2.fastq
Found 1054 instances of the forward adapter sequence in fastq/SRR21190757_1.fastq
Found 113 instances of the reverse adapter sequence in fastq/SRR21190757_2.fastq
Found 2271 instances of the forward adapter sequence in fastq/SRR21190758_1.fastq
Found 291 instances of the reverse adapter sequence in fastq/SRR21190758_2.fastq
Found 2866 instances of the forward adapter sequence in fastq/SRR21190759_1.fastq
Found 365 instances of the reverse adapter sequence in fastq/SRR21190759_2.fastq
Found 2019 instances of the forward adapter sequence in fastq/SRR21190760_1.fastq
Found 227 instances of the reverse adapter sequence in fastq/SRR21190760_2.fastq
Found 1951 instances of the forward adapter sequence in fastq/SRR21190761_1.fastq
Found 187 instances of the reverse adapter sequence in fastq/SRR21190761_2.fastq
Found 1723 instances of the forward adapter sequence in fastq/SRR21190762_1.fastq
Found 207 instances of the reverse adapter sequence in fastq/SRR21190762_2.fastq
Found 2604 instances of the forward adapter sequence in fastq/SRR21190763_1.fastq
Found 333 instances of the reverse adapter sequence in fastq/SRR21190763_2.fastq
Found 4818 instances of the forward adapter sequence in fastq/SRR21190764_1.fastq
Found 794 instances of the reverse adapter sequence in fastq/SRR21190764_2.fastq
Found 6579 instances of the forward adapter sequence in fastq/SRR21190765_1.fastq
Found 1071 instances of the reverse adapter sequence in fastq/SRR21190765_2.fastq
Found 6366 instances of the forward adapter sequence in fastq/SRR21190766_1.fastq
Found 1169 instances of the reverse adapter sequence in fastq/SRR21190766_2.fastq
Found 5101 instances of the forward adapter sequence in fastq/SRR21190767_1.fastq
Found 920 instances of the reverse adapter sequence in fastq/SRR21190767_2.fastq
Found 8104 instances of the forward adapter sequence in fastq/SRR21190768_1.fastq
Found 1580 instances of the reverse adapter sequence in fastq/SRR21190768_2.fastq
Found 3275 instances of the forward adapter sequence in fastq/SRR21190769_1.fastq
Found 413 instances of the reverse adapter sequence in fastq/SRR21190769_2.fastq
Found 8945 instances of the forward adapter sequence in fastq/SRR21190770_1.fastq
Found 1371 instances of the reverse adapter sequence in fastq/SRR21190770_2.fastq
Found 4592 instances of the forward adapter sequence in fastq/SRR21190771_1.fastq
Found 697 instances of the reverse adapter sequence in fastq/SRR21190771_2.fastq
Found 4857 instances of the forward adapter sequence in fastq/SRR21190772_1.fastq
Found 882 instances of the reverse adapter sequence in fastq/SRR21190772_2.fastq
Found 4420 instances of the forward adapter sequence in fastq/SRR21190773_1.fastq
Found 715 instances of the reverse adapter sequence in fastq/SRR21190773_2.fastq
Found 4435 instances of the forward adapter sequence in fastq/SRR21190774_1.fastq
Found 637 instances of the reverse adapter sequence in fastq/SRR21190774_2.fastq
Found 3292 instances of the forward adapter sequence in fastq/SRR21190775_1.fastq
Found 565 instances of the reverse adapter sequence in fastq/SRR21190775_2.fastq
```
Looks like the adapter sequences I found are fine, so we can jump to trimming.

cutadapt.sh:
```{bash, eval=FALSE}
#!/bin/bash

# Adapter sequences
FORWARD_ADAPTER="AAGTCGGAGGCCAAGCGGTCTTAGGAAGACAA"
REVERSE_ADAPTER="AAGTCGGATCGTAGCCATGTCGTTCTGTGAGCCAAGGAGTTG"

# Create a directory for the trimmed output if it doesn't exist
mkdir -p trimmed_fastq

# Loop through all the _1.fastq files in the fastq directory
for file in fastq/*_1.fastq; do
    # Identify the pair
    file1=$file
    file2=${file/_1.fastq/_2.fastq}

    # Generate output filenames
    out1=trimmed_fastq/$(basename "$file1" .fastq)_trimmed.fastq
    out2=trimmed_fastq/$(basename "$file2" .fastq)_trimmed.fastq

    # Run Cutadapt
    cutadapt \
        -a "$FORWARD_ADAPTER" -A "$REVERSE_ADAPTER" \
        -q 30 --pair-filter=any --minimum-length=30 \
        -o "$out1" -p "$out2" \
        "$file1" "$file2"
done
```
-q 30: This option trims low-quality ends from reads before adapter removal. The number 30 specifies the quality score threshold. In this case, bases with a quality score lower than 30 will be trimmed from the end of each read.

--pair-filter=any: This is used with paired-end reads. It indicates that if either the forward or reverse read of a pair needs to be discarded (for example, if after trimming it's too short), then both reads of the pair will be discarded,thus ensuring that the output maintains properly paired reads.

--minimum-length=30: This specifies the minimum length of reads to keep after trimming. Reads that are shorter than 30 bases after trimming will be discarded. This is useful for filtering out very short sequences that may not be useful for further analysis.

# 4. Removal of residual rRNA annotated in SILVA with BBDuk
The next step according to the protocol from the paper is to get rid of residual rRNA in our samples. This involves:

Downloading SSU (Small Subunit) and LSU (Large Subunit) Ref NR (Non-Redundant) datasets from silva. 

This can be done via silva_database_download.sh:
```{bash, eval=FALSE}
#!/bin/bash

# Downloading the SILVA LSU and SSU reference FASTA files
wget https://ftp.arb-silva.de/release_119.1/Exports/SILVA_119_LSURef_tax_silva.fasta.gz
wget https://ftp.arb-silva.de/release_119.1/Exports/SILVA_119.1_SSURef_Nr99_tax_silva.fasta.gz

# Decompressing the downloaded files
gunzip SILVA_119_LSURef_tax_silva.fasta.gz
gunzip SILVA_119.1_SSURef_Nr99_tax_silva.fasta.gz
```

And running bbduk.sh to actually remive residual rRNA:
```{bash, eval=FALSE}
#!/bin/bash

# Directory paths
TRIMMED_FASTQ_DIR="trimmed_fastq"
RRNA_REMOVED_DIR="rRNA_removed_fastq"
TEMP_DIR="temp_rRNA_removed"

# Reference databases (ensure these are in FASTA format)
LSU_DB="SILVA_119_LSURef_tax_silva.fasta"
SSU_DB="SILVA_119.1_SSURef_Nr99_tax_silva.fasta"

# Number of threads to use
THREADS=32

mkdir -p "$RRNA_REMOVED_DIR" "$TEMP_DIR"

# Function to run BBDuk for rRNA removal
run_bbduk() {
    local in1=$1
    local in2=$2
    local out1=$3
    local out2=$4
    local ref=$5

    bbduk.sh \
        in="$in1" \
        in2="$in2" \
        out="$out1" \
        out2="$out2" \
        ref="$ref" \
        k=31 \
        ktrim=n \
        mcf=0.5 \
        tbo \
        tpe \
        threads="$THREADS"
}

# Loop through all the trimmed FASTQ files in pairs
for file1 in "$TRIMMED_FASTQ_DIR"/*_1_trimmed.fastq; do
    file2="${file1%_1_trimmed.fastq}_2_trimmed.fastq"
    
    # Intermediate and final output filenames
    temp1="$TEMP_DIR/$(basename "$file1")"
    temp2="$TEMP_DIR/$(basename "$file2")"
    final1="$RRNA_REMOVED_DIR/$(basename "$file1" .fastq)_rRNA_removed.fastq"
    final2="$RRNA_REMOVED_DIR/$(basename "$file2" .fastq)_rRNA_removed.fastq"
    
    # Step 1: Remove LSU rRNA
    echo "Removing LSU rRNA for: $(basename "$file1") and $(basename "$file2")"
    run_bbduk "$file1" "$file2" "$temp1" "$temp2" "$LSU_DB"
    
    # Step 2: Remove SSU rRNA using the output from step 1 as input
    echo "Removing SSU rRNA for: $(basename "$file1") and $(basename "$file2")"
    run_bbduk "$temp1" "$temp2" "$final1" "$final2" "$SSU_DB"
    
    # Optional: Remove intermediate files
    rm "$temp1" "$temp2"
    
    echo "SSU and LSU rRNA removal done for: $(basename "$file1") and $(basename "$file2")"
done

echo "rRNA removal process completed."
```
in="$in1": Specifies the input file for the first mate in paired-end reads.

in2="$in2": Specifies the second mate in paired-end reads. 

out="$out1": Specifies the output file for processed first mates. 

out2="$out2": Specifies the output file for processed reads from the second input file in paired-end sequencing. 

ref="$ref": This parameter specifies the reference sequences to be used for trimming or filtering the reads..

k=31: Defines the k-mer length to be used for matching against the reference sequences. This is important for the specificity and sensitivity of the matching process.

ktrim=n: Indicates that k-mers found in reads should not be trimmed off. Instead, reads will be left intact even if matching k-mers are found. 

mcf=0.5: Sets the minimum coverage filter for trimming. It specifies the minimum fraction of bases that must match in a k-mer for it to be considered a valid match.

tbo: Stands for "trim by overlap". This option enables trimming of adapters based on paired-end read overlap detection, which can improve adapter removal when adapter sequences are not known or specified.

tpe: Enables "trim paired ends", which means that if adapters were trimmed from either read in a pair, the other read is trimmed by the same amount.

Now we can run multiqc again. 

processed_multiqc.sh:
```{bash, eval=FALSE}
#!/bin/bash

# Directory containing FASTQ files
FASTQ_DIR="rRNA_removed_fastq/"

# Output directory for FastQC results
OUTPUT_DIR="processed_fastqc_results"

# Create output directory if it doesn't exist
mkdir -p "$OUTPUT_DIR" multiqc

# Run FastQC on all FASTQ files in the directory
fastqc -o "$OUTPUT_DIR" -t 40 "$FASTQ_DIR"/*.fastq

# Run MultiQC to aggregate the FastQC reports
multiqc "$OUTPUT_DIR" -o processed_multiqc
```
<iframe src="multiqc_reports/multiqc_postprocessed.pdf" width="100%" height="600"></iframe>

# 5. Alignment with star
First, we should download hg38 assembly (used in the paper).

hg38.sh:
```{bash, eval=FALSE}
#!/bin/bash

wget ftp://ftp.ensembl.org/pub/release-104/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz

gunzip Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz
```
Create an index with index.sh:
```{bash, eval=FALSE}
#!/bin/bash

GENOME_FASTA="Homo_sapiens.GRCh38.dna.primary_assembl$
ANNOTATION_GTF="GSE211993_gencode_fantomcat.v1.02.gen$
STAR_INDEX_DIR="star_index"

mkdir -p "$STAR_INDEX_DIR"

# Run STAR in genomeGenerate mode
STAR --runThreadN 32 \
    --runMode genomeGenerate \
    --genomeDir "$STAR_INDEX_DIR" \
    --genomeFastaFiles "$GENOME_FASTA" \
    --sjdbGTFfile "$ANNOTATION_GTF" \  
    --sjdbOverhang 99 
    
echo "Indexing complete."
```
--runThreadN 32: Number of threads

--runMode genomeGenerate: This tells STAR to run in genome indexing mode.

--genomeDir "$STAR_INDEX_DIR": Specifies the directory where the generated genome indices will be stored.

--genomeFastaFiles "$GENOME_FASTA": Specifies the path to the FASTA files containing the reference genome sequences.

--sjdbGTFfile "$ANNOTATION_GTF": Specifies the path to the GTF file containing the genome annotation.

--sjdbOverhang 99: This parameter sets the length of the genomic sequence around the annotated junction to be used in constructing the splice junctions database. The value should be set to the read length minus 1. In this case, 99 suggests that the read length is expected to be 100 bases.


run STAR with star.sh:
```{bash, eval=FALSE}
#!/bin/bash

# Define the number of threads to use
THREADS=32

# Path to the STAR genome index
GENOME_DIR="star_index"

# Directory containing rRNA removed FASTQ files
FASTQ_DIR="rRNA_removed_fastq"

# Output directory for the alignments
ALIGNMENT_DIR="alignments"
mkdir -p "$ALIGNMENT_DIR"

# Loop through the FASTQ files in pairs
for R1 in "$FASTQ_DIR"/*_1_trimmed_rRNA_removed.fastq; do
    # Infer the name of the R2 file from the name of the R1 file
    R2="${R1%_1_trimmed_rRNA_removed.fastq}_2_trimmed_rRNA_removed.fastq"

    # Extract the base name for output naming
    SAMPLE_NAME=$(basename "$R1" _1_trimmed_rRNA_removed.fastq)

    echo "Processing $SAMPLE_NAME"

    # Run STAR for alignment
    STAR --runMode alignReads \
         --runThreadN $THREADS \
         --genomeDir "$GENOME_DIR" \
         --readFilesIn "$R1" "$R2" \
         --outFileNamePrefix "${ALIGNMENT_DIR}/${SAMPLE_NAME}." \
         --outSAMtype BAM SortedByCoordinate

    echo "Alignment completed for $SAMPLE_NAME"
done

echo "All sample alignments have been completed."
```
--runMode alignReads: This specifies the operation mode of STAR. alignReads tells STAR to perform the read alignment against the prepared genome index.

--runThreadN Number of threads

--genomeDir "$GENOME_DIR": This sets the path to the directory containing the genome index files that were previously generated with STAR in genomeGenerate mode.

--readFilesIn "$R1" "$R2": Specifies the input files containing the RNA-seq reads.

--outFileNamePrefix "${ALIGNMENT_DIR}/${SAMPLE_NAME}.": This parameter sets the prefix for all output files generated by STAR.

--outSAMtype BAM SortedByCoordinate: This tells STAR to output the alignment results in BAM format, sorted by genomic coordinates. 

Checking mapping with MultiQC. mapping_quality.sh:
```{bash, eval=FALSE}
#!/bin/bash

# Define the directory containing STAR output files
STAR_OUTPUT_DIR="alignments"

# Define the directory where you want to save the MultiQC report
REPORT_DIR="$(pwd)/star_multiqc_report"

# Run MultiQC on the STAR outputs
echo "Running MultiQC on the STAR outputs..."
multiqc $STAR_OUTPUT_DIR -o $REPORT_DIR
```
Output:
<iframe src="multiqc_reports/star_multiqc_report.pdf" width="100%" height="600"></iframe>

# 6. FeatureCounts
featurecounts.sh:
```{bash, eval=FALSE}
#!/bin/bash

# Path to the directory containing BAM files
BAM_DIR="alignments"

# Path to the GTF annotation file
ANNOTATION_FILE="GSE211993_gencode_fantomcat.v1.02.genes_transcripts_exons.gtf"

# Output directory for featureCounts results
OUTPUT_DIR="featureCounts_results"
mkdir -p "$OUTPUT_DIR"

# Output file name
OUTPUT_FILE="${OUTPUT_DIR}/featureCounts_results.txt"

# Run featureCounts
featureCounts -a "$ANNOTATION_FILE" \
              -o "$OUTPUT_FILE" \
              -F GTF \
              -t exon \
              -g gene_id \
              -p \
              --countReadPairs \
              --minOverlap 90 \
              --fracOverlap 0.9 \
              -T 32 \
              "$BAM_DIR"/*.bam

echo "featureCounts has completed."
```
-a "$ANNOTATION_FILE": Specifies the annotation file.

-o "$OUTPUT_FILE": Designates the output file that will contain the counts of reads for each feature.

-F GTF: Indicates the format of the annotation file. In this case, it's specified as GTF.

-t exon: Specifies the type of feature to count reads against. Here, exon means that reads will be counted if they map to exon regions defined in the annotation file.

-g ref_gene: This option sets the attribute in the annotation file that will be used to group features (e.g., exons) into meta-features (e.g., genes) for counting.

-O: Allows reads to be assigned to more than one feature if they overlap multiple features. This is important for reads that might map to regions where features overlap (e.g., alternative splicing sites).

--minOverlap 90: Sets the minimum number of overlapping bases required for a read to be considered as overlapping with a feature. In this case, a read must overlap a feature by at least 90 bases to be counted.

--fracOverlap 0.9: Specifies the minimum fraction of overlapping bases in a read that must overlap with a feature for the read to be considered. 

--primary: Only counts primary alignments of reads. This is used to exclude secondary or supplementary alignments, which is important for ensuring that each read is counted only once, especially in the presence of multimapping reads.

-p: Indicates that the input data are paired-end reads. This option tells featureCounts to count fragments (pair of reads) instead of individual reads, which is the correct approach for paired-end RNA-seq data.

-B: Requires both ends of a pair to be successfully aligned for a fragment to be considered. This helps ensure that only high-quality, properly aligned read pairs are counted.

-C: Excludes reads that have their two ends mapping to different chromosomes or mapping to the same chromosome but on opposite strands, to filter out chimeric or improperly paired reads.

-T 32: Specifies the number of threads to use for processing.

"$BAM_DIR"/*.bam: Specifies the input BAM files containing the aligned reads.

# 7. Gene count summary
Important information:I will be looking only at L150P, I will get rid of A79V samples and leave only 10 L150P samples, 5 control and 5 with familial AD. At one point I have realized that 10 samples are low-quality

Summary plot is interactive and can be zoomed in/out
```{r}
# Load necessary libraries
library(dplyr)
library(ggplot2)
library(reshape2)
library(plotly)
library(stringr)
library(DESeq2)
library(ggrepel)

# Read the gene count summary and metadata files
gene_count_summary <- read.table("count_table.txt.summary", header = TRUE, stringsAsFactors = FALSE)
metadata <- read.csv("metadata.txt", stringsAsFactors = FALSE)

# Mapping and column name update with vectorized operations
metadata$genotype <- gsub("- gene corrected", "GC", metadata$genotype)
srr_to_genotype <- setNames(metadata$genotype, metadata$Run)

# Update column names in gene_count_summary based on SRR numbers
colnames(gene_count_summary)[-1] <- sapply(colnames(gene_count_summary)[-1], function(name) {
  srr_number <- regmatches(name, regexpr("SRR[0-9]+", name))
  if(length(srr_number) > 0 && !is.na(srr_to_genotype[srr_number])) srr_to_genotype[srr_number] else name
})

# Function to rename duplicates with suffixes
rename_duplicates <- function(names) {
  # Create a counter for each unique name
  counts <- rep(0, length(names))
  names_with_counts <- names
  for (i in seq_along(names)) {
    counts[i] <- sum(names[1:i] == names[i])
    if (counts[i] > 1) {
      names_with_counts[i] <- paste(names[i], counts[i], sep = "_")
    }
  }
  names_with_counts
}

# Applying the function to rename columns
names(gene_count_summary) <- rename_duplicates(names(gene_count_summary))


# Reorder the dataframe columns based on sorted names directly
gene_count_summary <- gene_count_summary[, c("Status", sort(names(gene_count_summary)[-1]))]

# Filter rows before melting to reduce the amount of data processed
gene_count_summary_filtered <- gene_count_summary %>% 
   dplyr::filter(Status %in% c("Assigned", "Unassigned_MultiMapping", "Unassigned_NoFeatures", "Unassigned_Overlapping_Length"))

# Melt the data
gene_count_long <- melt(gene_count_summary_filtered, id.vars = "Status", variable.name = "Sample", value.name = "Count")

# Create a unique identifier for each replicate
gene_count_long <- gene_count_long %>%
  group_by(Sample) %>%
  mutate(Replicate = paste(Sample, row_number(), sep = "_")) %>%
  ungroup()

# As I will be looking only at L150P, I will get rid of A79V samples and leave only 5 L150P samples
filtered_gene_count_long <- gene_count_long %>%
  dplyr::filter(!str_detect(Sample, "A79V")) %>%
  dplyr::slice(-c(1:4)) %>%
  dplyr::slice(-c(5:20)) %>%
  dplyr::slice(-c(21:24)) %>%
  dplyr::slice(-c(25:40))

# Plotting
p <- ggplot(filtered_gene_count_long, aes(y = Sample, x = Count, fill = Status)) +
  geom_bar(stat = "identity", position = "dodge", orientation = "y") +
  theme_minimal() +
  labs(title = "Counts for Each Replicate and Status", y = "Replicate", x = "Count") +
  scale_fill_brewer(palette = "Set3") # Adjust palette as needed

# Convert ggplot object to an interactive plotly object
ggplotly(p)
```
The majority of counts for each replicate fall under the 'Assigned' category, indicating successful mapping to known genomic features, while the other categories represent various types of reads that could not be uniquely or properly assigned. This distribution suggests a consistent pattern of read assignment across the replicates, with a relatively small fraction of reads being unassigned or ambiguously mapped.

# Now lets process the count table
```{r}
# Read the gene count summary and metadata files
count_table <- read.table("count_table.txt", header = TRUE, stringsAsFactors = FALSE)

# mapping and column name update with vectorized operations
metadata$genotype <- gsub("- gene corrected", "GC", metadata$genotype)
srr_to_genotype <- setNames(metadata$genotype, metadata$Run)

# Update column names based on SRR numbers
colnames(count_table)[7:ncol(count_table)] <- sapply(colnames(count_table)[7:ncol(count_table)], function(name) {
  srr_number <- regmatches(name, regexpr("SRR[0-9]+", name))
  if(length(srr_number) > 0 && !is.na(srr_to_genotype[srr_number])) {
    srr_to_genotype[srr_number]
  } else {
    name
  }
})


# Extract the gene identifiers (or names) to use as row names
gene_ids <- count_table[, 1]

# Extract the count data, excluding the first column and non-count columns
count_data <- count_table[, 7:ncol(count_table)] # Adjust indices as necessary

# Convert to matrix if it's not already one
count_data_matrix <- as.matrix(count_data)

# Assign gene identifiers as row names to the matrix
rownames(count_data_matrix) = gene_ids

count_data_matrix <- count_data_matrix[, order(colnames(count_data_matrix))]

# As I will be looking only at L150P, I will get rid of A79V samples and first 5 L150P samples
filtered_count_data_matrix <- count_data_matrix[, -c(1:20)]
filtered_count_data_matrix <- filtered_count_data_matrix[, -c(1:5)]
filtered_count_data_matrix <- filtered_count_data_matrix[, -c(6:10)]
```

```{r}
colData <- data.frame(
  condition = factor(c("L150P", "L150P", "L150P","L150P","L150P", "Control", "Control","Control","Control","Control" ))
)
rownames(colData) = colnames(filtered_count_data_matrix)
```

Running DESeq2 on L150P and Control samples
```{r}
dds<- DESeqDataSetFromMatrix(
  countData = filtered_count_data_matrix,
  colData = colData,
  design = ~ condition
)

dds <- DESeq(dds)

results <- results(dds)

resultsOrdered <- results[order(results$pvalue),]

```
MA Plot
```{r}
plotMA(results, main="MA-plot", ylim=c(-10,10))
```
The blue points represent genes that are significantly differentially expressed, with their dispersion reflecting the strength and direction of differential expression. The majority of genes do not exhibit significant changes in expression (grey points), indicating stable expression across the conditions compared. The clustering of blue points away from the zero log fold change line, especially for genes with higher mean expression levels, suggests a set of genes with notable expression differences that may be biologically significant in the context of the L150P variant.

PCA plot:
```{r}
rld <- rlogTransformation(dds)
plotPCA(rld, intgroup="condition")

pcaData <- plotPCA(rld, intgroup="condition", returnData=TRUE)
pcaData$sample <- rownames(pcaData)

ggplot(pcaData, aes(x=PC1, y=PC2, label=sample)) +
  geom_point(aes(color=condition), size=2) +
  geom_text_repel(aes(color=condition), size=3) +
  theme_minimal() +
  ggtitle("PCA of rlog-transformed counts with Sample Labels") +
  xlab(paste0("PC1 (", round(100 * attr(pcaData, "percentVar")[1]), "% variance)")) +
  ylab(paste0("PC2 (", round(100 * attr(pcaData, "percentVar")[2]), "% variance)")) +
  scale_color_manual(values=c("Condition1"="blue", "Condition2"="red"))

```

The PCA plot illustrates the separation between the control group and the L150P variant samples, with principal component 1 (PC1) accounting for 98% of the variance. The distinct clustering of the L150P samples away from the control on PC1 suggests a significant impact of the L150P mutation on the overall gene expression profile. The variance captured by PC2 is relatively small, indicating that most of the expression variation is explained by PC1. This separation supports the potential of the L150P mutation to drive distinct transcriptional changes.

Number of Differentially expressed genes:
```{r}
res<- results(dds)

significant_genes <- res[which(res$padj <0.05), ]

significant_fold_change_genes<- significant_genes[which(abs(significant_genes$log2FoldChange)>1),]
```

Summary of the results:
```{r}
cat("Number of significant genes: ", nrow(significant_genes), "\n")
cat("Number of significant genes with |log2FoldChange| > 1: ", nrow(significant_fold_change_genes), "\n")

# Viewing the top significant genes
head(significant_fold_change_genes)
```

Volcano plot:
```{r}
plot(significant_genes$log2FoldChange, -log10(significant_genes$pvalue),
     pch=20, main="Volcano Plot", xlab="Log2 Fold Change", ylab="-Log10 p-value")
points(significant_fold_change_genes$log2FoldChange, -log10(significant_fold_change_genes$pvalue),
       col="red", pch=20)

```
The density of points in the significant regions suggests a substantial number of genes are differentially expressed.

Heatmap:
```{r}
library(pheatmap)

selected_genes <- rownames(significant_fold_change_genes)
rlog_counts <- assay(rlogTransformation(dds))
pheatmap(rlog_counts[selected_genes, ], cluster_rows=TRUE, show_rownames=FALSE,
         cluster_cols=TRUE, annotation_col=as.data.frame(colData))

```
GO Enrichment analysis:

Preparation for actual analysis:
```{r}
library(clusterProfiler)
library(AnnotationDbi)
library(ensembldb)
library(EnsDb.Hsapiens.v86)  
library(org.Hs.eg.db)
library(DT)


gene_list <- rownames(significant_fold_change_genes)

gene_list <- sapply(gene_list, function(x) {
  if(grepl("^ENSG", x)) {  # Check if the gene ID starts with "ENSG"
    sub("\\..*$", "", x)  # Remove dot and everything after
  } else {
    x
  }
}, USE.NAMES = FALSE)
```
Biological Processes:
```{r}
ego <- enrichGO(gene         = gene_list,
                OrgDb         = org.Hs.eg.db,
                keyType      = "ENSEMBL",
                ont          = "BP",
                pAdjustMethod = "BH",
                qvalueCutoff  = 0.05,
                readable      = TRUE)

ego_df <- as.data.frame(ego)

datatable(head(ego_df), options = list(pageLength = 5), 
          caption = 'Top GO Terms from Enrichment Analysis (BP)')

dotplot(ego)
```

Cellular component:
```{r}
ego <- enrichGO(gene         = gene_list,
                OrgDb         = org.Hs.eg.db,
                keyType      = "ENSEMBL",
                ont          = "CC",
                pAdjustMethod = "BH",
                qvalueCutoff  = 0.05,
                readable      = TRUE)

ego_df <- as.data.frame(ego)

datatable(head(ego_df), options = list(pageLength = 5), 
          caption = 'Top GO Terms from Enrichment Analysis (CC)')

dotplot(ego)
```


Molecular function:
```{r}
ego <- enrichGO(gene         = gene_list,
                OrgDb         = org.Hs.eg.db,
                keyType      = "ENSEMBL",
                ont          = "MF",
                pAdjustMethod = "BH",
                qvalueCutoff  = 0.05,
                readable      = TRUE)

ego_df <- as.data.frame(ego)

datatable(head(ego_df), options = list(pageLength = 5), 
          caption = 'Top GO Terms from Enrichment Analysis (MF)')

dotplot(ego)
```
```{r}
library(biomaRt)

ensembl <- useMart("ensembl", dataset = "hsapiens_gene_ensembl")

cage_gene_ids <- c("CATG00000000442.1", "CATG00000000487.1", "CATG00000000490.1")

gene_mapping <- getBM(attributes = c('ensembl_gene_id', 'hgnc_symbol'),
                      filters = 'ensembl_gene_id',
                      values = cage_gene_ids,
                      mart = ensembl)

```


